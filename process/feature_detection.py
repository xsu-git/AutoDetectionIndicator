#!/usr/bin/env python
# -*- coding: utf-8 -*-
'''
@Time              @Author    @Version    @Desciption
---------------    -------    --------    -----------
2025/9/3 10:25     Xsu         1.0         None
'''

import pandas as pd
import numpy as np
from sklearn.ensemble import RandomForestClassifier, GradientBoostingRegressor
from sklearn.model_selection import TimeSeriesSplit, cross_val_score
from sklearn.preprocessing import StandardScaler, RobustScaler
from sklearn.metrics import classification_report, accuracy_score
import talib
from scipy import stats
from scipy.signal import savgol_filter
from process.loader import load_process_data
from utils.data_preprocess_util import restore_hook,build_data_dir
from pathlib import Path
import json
from utils import logBot
from tqdm import tqdm

import warnings
warnings.filterwarnings('ignore')


class PeakFeatureEngineer:
    """
    å³°å€¼ç‰¹å¾å·¥ç¨‹å¸ˆ - åå°”è¡—é‡åŒ–çº§åˆ«
    ä»æ£€æµ‹åˆ°çš„å³°å€¼ç‚¹ä½ä¸­æå–130+ç»´äº¤æ˜“ç‰¹å¾
    """

    def __init__(self, lookback_periods=[3, 5, 8, 13, 21]):
        self.lookback_periods = lookback_periods
        self.feature_names = []

    def extract_comprehensive_features(self, df: pd.DataFrame, peaks_results: dict) -> pd.DataFrame:
        """
        æå–ç»¼åˆç‰¹å¾çŸ©é˜µ

        ç‰¹å¾ç±»åˆ«ï¼š
        1. å³°å€¼ç»“æ„ç‰¹å¾ (20ç»´)
        2. ä»·æ ¼åŠ¨é‡ç‰¹å¾ (25ç»´) 
        3. æ³¢åŠ¨ç‡ç»“æ„ç‰¹å¾ (15ç»´)
        4. æˆäº¤é‡ç‰¹å¾ (20ç»´)
        5. æŠ€æœ¯æŒ‡æ ‡ç‰¹å¾ (25ç»´)
        6. å¸‚åœºå¾®ç»“æ„ç‰¹å¾ (15ç»´)
        7. å³°å€¼æ—¶é—´ç‰¹å¾ (10ç»´)
        """
        logBot.info("Start Extraction feature engineering...")
        df_tech = self._calculate_technical_base(df)
        logBot.info("Compute Base Technical indicators Finish")

        # åˆ›å»ºå³°å€¼æ ‡è®°
        df_tech['is_peak'] = 0
        df_tech['peak_type'] = 0  # -1: low, 0: none, 1: high
        df_tech['peak_score'] = 0.0

        # æ ‡è®°é«˜ä½ç‚¹
        for high in peaks_results['highs']:
            idx = high['index']
            if idx < len(df_tech):
                df_tech.iloc[idx, df_tech.columns.get_loc('is_peak')] = 1
                df_tech.iloc[idx, df_tech.columns.get_loc('peak_type')] = 1
                df_tech.iloc[idx, df_tech.columns.get_loc('peak_score')] = high['score']

        for low in peaks_results['lows']:
            idx = low['index']
            if idx < len(df_tech):
                df_tech.iloc[idx, df_tech.columns.get_loc('is_peak')] = 1
                df_tech.iloc[idx, df_tech.columns.get_loc('peak_type')] = -1
                df_tech.iloc[idx, df_tech.columns.get_loc('peak_score')] = low['score']

        # æå–å„ç±»ç‰¹å¾
        features_df = pd.DataFrame(index=df_tech.index)

        # 1. å³°å€¼ç»“æ„ç‰¹å¾
        logBot.info("Start extract peak structure features")
        peak_structure_features = self._extract_peak_structure_features(df_tech, peaks_results)



        features_df = pd.concat([features_df, peak_structure_features], axis=1)

        # 2. ä»·æ ¼åŠ¨é‡ç‰¹å¾
        logBot.info("Start extract Price Momentum features")
        momentum_features = self._extract_momentum_features(df_tech)
        features_df = pd.concat([features_df, momentum_features], axis=1)

        # 3. æ³¢åŠ¨ç‡ç»“æ„ç‰¹å¾
        logBot.info("Start extract volatility structure features")
        volatility_features = self._extract_volatility_features(df_tech)
        features_df = pd.concat([features_df, volatility_features], axis=1)

        # 4. æˆäº¤é‡ç‰¹å¾
        logBot.info("Start extract volume structure features")
        volume_features = self._extract_volume_features(df_tech)
        features_df = pd.concat([features_df, volume_features], axis=1)

        # 5. æŠ€æœ¯æŒ‡æ ‡ç‰¹å¾
        logBot.info("Start extract technical structure features")
        technical_features = self._extract_technical_features(df_tech)
        features_df = pd.concat([features_df, technical_features], axis=1)

        # 6. å¸‚åœºå¾®ç»“æ„ç‰¹å¾
        microstructure_features = self._extract_microstructure_features(df_tech)
        features_df = pd.concat([features_df, microstructure_features], axis=1)

        # 7. å³°å€¼æ—¶é—´ç‰¹å¾
        temporal_features = self._extract_temporal_features(df_tech)
        features_df = pd.concat([features_df, temporal_features], axis=1)

        # æ·»åŠ ç›®æ ‡å˜é‡
        features_df = self._create_target_variables(features_df, df_tech)

        return features_df.dropna()

    def _calculate_technical_base(self, df: pd.DataFrame) -> pd.DataFrame:
        """è®¡ç®—åŸºç¡€æŠ€æœ¯æŒ‡æ ‡"""
        df_tech = df.copy()

        # åŸºç¡€ä»·æ ¼æŒ‡æ ‡
        df_tech['hl2'] = (df_tech['high'] + df_tech['low']) / 2
        df_tech['hlc3'] = (df_tech['high'] + df_tech['low'] + df_tech['close']) / 3
        df_tech['ohlc4'] = (df_tech['open'] + df_tech['high'] + df_tech['low'] + df_tech['close']) / 4

        # ç§»åŠ¨å‡çº¿æ—
        for period in [5, 10, 20, 50]:
            df_tech[f'sma_{period}'] = talib.SMA(df_tech['close'], timeperiod=period)
            df_tech[f'ema_{period}'] = talib.EMA(df_tech['close'], timeperiod=period)

        # æ³¢åŠ¨ç‡æŒ‡æ ‡
        df_tech['atr_14'] = talib.ATR(df_tech['high'], df_tech['low'], df_tech['close'], timeperiod=14)
        df_tech['atr_7'] = talib.ATR(df_tech['high'], df_tech['low'], df_tech['close'], timeperiod=7)

        # åŠ¨é‡æŒ‡æ ‡
        df_tech['rsi_14'] = talib.RSI(df_tech['close'], timeperiod=14)
        df_tech['rsi_7'] = talib.RSI(df_tech['close'], timeperiod=7)

        # MACD
        df_tech['macd'], df_tech['macd_signal'], df_tech['macd_hist'] = talib.MACD(df_tech['close'])

        # å¸ƒæ—å¸¦
        df_tech['bb_upper'], df_tech['bb_middle'], df_tech['bb_lower'] = talib.BBANDS(df_tech['close'])
        df_tech['bb_width'] = (df_tech['bb_upper'] - df_tech['bb_lower']) / df_tech['bb_middle']
        df_tech['bb_position'] = (df_tech['close'] - df_tech['bb_lower']) / (df_tech['bb_upper'] - df_tech['bb_lower'])
        return df_tech

    def _extract_peak_structure_features(self, df_tech: pd.DataFrame, peaks_results: dict) -> pd.DataFrame:
        """æå–å³°å€¼ç»“æ„ç‰¹å¾"""
        features = pd.DataFrame(index=df_tech.index)

        # å³°å€¼å¯†åº¦ç‰¹å¾
        for window in [10, 20, 50]:
            peak_density = df_tech['is_peak'].rolling(window=window).sum()
            features[f'peak_density_{window}'] = peak_density / window

        # å³°å€¼å¼ºåº¦åˆ†å¸ƒ
        for window in [10, 20]:
            features[f'peak_score_mean_{window}'] = df_tech['peak_score'].rolling(window=window).mean()
            features[f'peak_score_std_{window}'] = df_tech['peak_score'].rolling(window=window).std()

        # é«˜ä½ç‚¹æ¯”ç‡
        for window in [20, 50]:
            high_count = (df_tech['peak_type'] == 1).rolling(window=window).sum()
            low_count = (df_tech['peak_type'] == -1).rolling(window=window).sum()
            features[f'high_low_ratio_{window}'] = high_count / (low_count + 1)

        # è·ç¦»ä¸Šæ¬¡å³°å€¼çš„æ—¶é—´
        features['bars_since_last_peak'] = self._bars_since_last_event(df_tech['is_peak'])
        features['bars_since_last_high'] = self._bars_since_last_event(df_tech['peak_type'] == 1)
        features['bars_since_last_low'] = self._bars_since_last_event(df_tech['peak_type'] == -1)

        # å³°å€¼ä»·æ ¼è·ç¦»
        features['price_to_last_high'] = self._price_distance_to_last_peak(df_tech, 1)
        features['price_to_last_low'] = self._price_distance_to_last_peak(df_tech, -1)

        # å³°å€¼è¶‹åŠ¿ç‰¹å¾
        features['peak_trend_5'] = self._calculate_peak_trend(df_tech, 5)
        features['peak_trend_10'] = self._calculate_peak_trend(df_tech, 10)

        return features

    def _extract_momentum_features(self, df_tech: pd.DataFrame) -> pd.DataFrame:
        """æå–ä»·æ ¼åŠ¨é‡ç‰¹å¾"""
        features = pd.DataFrame(index=df_tech.index)

        # å¤šå‘¨æœŸä»·æ ¼å˜åŒ–ç‡
        for period in [1, 3, 5, 10, 20]:
            features[f'price_change_{period}'] = df_tech['close'].pct_change(period)
            features[f'high_change_{period}'] = df_tech['high'].pct_change(period)
            features[f'low_change_{period}'] = df_tech['low'].pct_change(period)

        # ä»·æ ¼åŠ¨é‡æŒ‡æ ‡
        for period in [5, 10, 20]:
            features[f'momentum_{period}'] = talib.MOM(df_tech['close'], timeperiod=period)
            features[f'roc_{period}'] = talib.ROC(df_tech['close'], timeperiod=period)

        # ç›¸å¯¹å¼ºå¼±æŒ‡æ ‡
        features['rsi_momentum'] = df_tech['rsi_14'].diff()
        features['rsi_acceleration'] = features['rsi_momentum'].diff()

        # ä»·æ ¼åŠ é€Ÿåº¦
        features['price_acceleration'] = df_tech['close'].diff().diff()

        # åŠ¨é‡å‘æ•£
        features['momentum_divergence_5'] = self._calculate_momentum_divergence(df_tech, 5)
        features['momentum_divergence_10'] = self._calculate_momentum_divergence(df_tech, 10)

        return features

    def _extract_volatility_features(self, df_tech: pd.DataFrame) -> pd.DataFrame:
        """æå–æ³¢åŠ¨ç‡ç»“æ„ç‰¹å¾"""
        features = pd.DataFrame(index=df_tech.index)

        # çœŸå®æ³¢åŠ¨ç‡
        for period in [5, 10, 20]:
            returns = df_tech['close'].pct_change()
            features[f'realized_vol_{period}'] = returns.rolling(window=period).std() * np.sqrt(period)

        # ATRç›¸å…³ç‰¹å¾
        features['atr_ratio'] = df_tech['atr_7'] / df_tech['atr_14']
        features['atr_percentile'] = df_tech['atr_14'].rolling(50).rank(pct=True)

        # ä»·æ ¼èŒƒå›´ç‰¹å¾
        features['daily_range'] = (df_tech['high'] - df_tech['low']) / df_tech['close']
        features['body_ratio'] = abs(df_tech['close'] - df_tech['open']) / (df_tech['high'] - df_tech['low'] + 1e-8)

        # æ³¢åŠ¨ç‡çŠ¶æ€
        features['vol_regime'] = self._identify_volatility_regime(df_tech)

        # Gapç‰¹å¾
        features['gap_up'] = np.where(df_tech['open'] > df_tech['close'].shift(1),
                                      (df_tech['open'] - df_tech['close'].shift(1)) / df_tech['close'].shift(1), 0)
        features['gap_down'] = np.where(df_tech['open'] < df_tech['close'].shift(1),
                                        (df_tech['close'].shift(1) - df_tech['open']) / df_tech['close'].shift(1), 0)

        # å¸ƒæ—å¸¦æ³¢åŠ¨ç‡
        features['bb_squeeze'] = np.where(df_tech['bb_width'] < df_tech['bb_width'].rolling(20).quantile(0.2), 1, 0)
        features['bb_expansion'] = np.where(df_tech['bb_width'] > df_tech['bb_width'].rolling(20).quantile(0.8), 1, 0)

        return features

    def _calculate_vpt_optimized(self, close, volume):
        """
        VPTè®¡ç®—çš„ä¼˜åŒ–ç‰ˆæœ¬ - ä½¿ç”¨pandaså†…ç½®å‡½æ•°
        """
        # è®¡ç®—ä»·æ ¼å˜åŒ–ç‡
        price_pct_change = close.pct_change()

        # è®¡ç®—VPTå¢é‡
        vpt_increments = volume * price_pct_change

        # ç´¯ç§¯æ±‚å’Œï¼Œç¬¬ä¸€ä¸ªå€¼ä¸º0
        vpt = vpt_increments.fillna(0).cumsum()

        return vpt

    def _extract_volume_features(self, df_tech: pd.DataFrame) -> pd.DataFrame:
        """æå–æˆäº¤é‡ç‰¹å¾"""
        features = pd.DataFrame(index=df_tech.index)

        # æˆäº¤é‡ç§»åŠ¨å‡çº¿
        for period in [5, 10, 20]:
            features[f'vol_sma_{period}'] = df_tech['volume'].rolling(period).mean()
            features[f'vol_ratio_{period}'] = df_tech['volume'] / features[f'vol_sma_{period}']

        # æˆäº¤é‡ä»·æ ¼è¶‹åŠ¿
        # features['vpt'] = talib.VPT(df_tech['close'], df_tech['volume'])
        features['vpt'] = self._calculate_vpt_optimized(df_tech['close'], df_tech['volume'])
        features['obv'] = talib.OBV(df_tech['close'], df_tech['volume'])

        # èµ„é‡‘æµæŒ‡æ ‡
        features['mfi'] = talib.MFI(df_tech['high'], df_tech['low'], df_tech['close'], df_tech['volume'])
        features['ad'] = talib.AD(df_tech['high'], df_tech['low'], df_tech['close'], df_tech['volume'])

        # æˆäº¤é‡åˆ†å¸ƒ
        features['vol_percentile'] = df_tech['volume'].rolling(50).rank(pct=True)

        # å¼‚å¸¸æˆäº¤é‡
        vol_threshold = df_tech['volume'].rolling(20).mean() + 2 * df_tech['volume'].rolling(20).std()
        features['volume_spike'] = (df_tech['volume'] > vol_threshold).astype(int)

        # ä»·é‡å…³ç³»
        price_change = df_tech['close'].pct_change()
        features['price_volume_corr_10'] = price_change.rolling(10).corr(df_tech['volume'].pct_change())

        # VWAPç›¸å…³
        if 'vwap' not in df_tech.columns:
            df_tech['vwap'] = (df_tech['close'] * df_tech['volume']).rolling(20).sum() / df_tech['volume'].rolling(
                20).sum()

        features['price_to_vwap'] = df_tech['close'] / df_tech['vwap'] - 1

        return features

    def _extract_technical_features(self, df_tech: pd.DataFrame) -> pd.DataFrame:
        """æå–æŠ€æœ¯æŒ‡æ ‡ç‰¹å¾"""
        features = pd.DataFrame(index=df_tech.index)

        # RSIç‰¹å¾æ—
        features['rsi_oversold'] = (df_tech['rsi_14'] < 30).astype(int)
        features['rsi_overbought'] = (df_tech['rsi_14'] > 70).astype(int)
        features['rsi_divergence'] = self._calculate_rsi_divergence(df_tech)

        # MACDç‰¹å¾
        features['macd_signal_cross'] = self._detect_signal_cross(df_tech['macd'], df_tech['macd_signal'])
        features['macd_histogram_peak'] = self._detect_histogram_peaks(df_tech['macd_hist'])
        features['macd_zero_cross'] = self._detect_signal_cross(df_tech['macd'], pd.Series(0, index=df_tech.index))

        # ç§»åŠ¨å‡çº¿ç‰¹å¾
        features['ma_cross_5_20'] = self._detect_signal_cross(df_tech['sma_5'], df_tech['sma_20'])
        features['ma_cross_10_50'] = self._detect_signal_cross(df_tech['sma_10'], df_tech['sma_50'])

        # å¸ƒæ—å¸¦ç‰¹å¾
        features['bb_upper_touch'] = (df_tech['high'] >= df_tech['bb_upper']).astype(int)
        features['bb_lower_touch'] = (df_tech['low'] <= df_tech['bb_lower']).astype(int)
        features['bb_middle_cross'] = self._detect_signal_cross(df_tech['close'], df_tech['bb_middle'])

        # æ”¯æ’‘é˜»åŠ›çªç ´
        features['support_break'] = self._detect_support_resistance_break(df_tech, 'support')
        features['resistance_break'] = self._detect_support_resistance_break(df_tech, 'resistance')

        # è¶‹åŠ¿å¼ºåº¦
        features['trend_strength'] = self._calculate_trend_strength(df_tech)

        # å¸‚åœºçŠ¶æ€
        features['market_regime'] = self._identify_market_regime(df_tech)

        return features

    def _extract_microstructure_features(self, df_tech: pd.DataFrame) -> pd.DataFrame:
        """æå–å¸‚åœºå¾®ç»“æ„ç‰¹å¾"""
        features = pd.DataFrame(index=df_tech.index)

        # ä¹°å–å‹åŠ›
        features['buying_pressure'] = (df_tech['close'] - df_tech['low']) / (df_tech['high'] - df_tech['low'] + 1e-8)
        features['selling_pressure'] = (df_tech['high'] - df_tech['close']) / (df_tech['high'] - df_tech['low'] + 1e-8)

        # Kçº¿å½¢æ€
        features['doji'] = (
                    abs(df_tech['close'] - df_tech['open']) / (df_tech['high'] - df_tech['low'] + 1e-8) < 0.1).astype(
            int)
        features['hammer'] = self._identify_hammer_pattern(df_tech)
        features['engulfing'] = self._identify_engulfing_pattern(df_tech)

        # ä»·æ ¼æ•ˆç‡
        features['price_efficiency_5'] = self._calculate_price_efficiency(df_tech['close'], 5)
        features['price_efficiency_10'] = self._calculate_price_efficiency(df_tech['close'], 10)

        # æµåŠ¨æ€§æŒ‡æ ‡
        features['bid_ask_proxy'] = (df_tech['high'] - df_tech['low']) / df_tech['volume']

        # ä»·æ ¼å†²å‡»
        features['price_impact'] = abs(df_tech['close'].pct_change()) / (df_tech['volume'].pct_change() + 1e-8)

        return features

    def _extract_temporal_features(self, df_tech: pd.DataFrame) -> pd.DataFrame:
        """æå–æ—¶é—´ç‰¹å¾"""
        features = pd.DataFrame(index=df_tech.index)

        # æ—¶é—´å‘¨æœŸç‰¹å¾
        features['hour'] = df_tech.index.hour
        features['day_of_week'] = df_tech.index.dayofweek
        features['is_weekend'] = (df_tech.index.dayofweek >= 5).astype(int)

        # å¸‚åœºå¼€ç›˜æ—¶é—´ç‰¹å¾ï¼ˆåŠ å¯†è´§å¸24å°æ—¶ï¼Œä½†ä»æœ‰é«˜ä½æ´»è·ƒæœŸï¼‰
        features['is_asian_session'] = ((df_tech.index.hour >= 0) & (df_tech.index.hour < 8)).astype(int)
        features['is_european_session'] = ((df_tech.index.hour >= 8) & (df_tech.index.hour < 16)).astype(int)
        features['is_us_session'] = ((df_tech.index.hour >= 16) & (df_tech.index.hour < 24)).astype(int)

        # å‘¨æœŸæ€§æ¨¡å¼
        features['hour_sin'] = np.sin(2 * np.pi * df_tech.index.hour / 24)
        features['hour_cos'] = np.cos(2 * np.pi * df_tech.index.hour / 24)
        features['day_sin'] = np.sin(2 * np.pi * df_tech.index.dayofweek / 7)
        features['day_cos'] = np.cos(2 * np.pi * df_tech.index.dayofweek / 7)

        return features

    def _create_target_variables(self, features_df: pd.DataFrame, df_tech: pd.DataFrame) -> pd.DataFrame:
        """åˆ›å»ºç›®æ ‡å˜é‡"""

        # å‰ç»æ”¶ç›Šç‡ç›®æ ‡
        for period in [1, 3, 5, 10]:
            features_df[f'future_return_{period}'] = df_tech['close'].pct_change(period).shift(-period)

        # åˆ†ç±»ç›®æ ‡ï¼šæœªæ¥æ˜¯å¦ä¼šå‡ºç°æ˜¾è‘—ä»·æ ¼ç§»åŠ¨
        threshold = df_tech['atr_14'].rolling(20).mean()
        features_df['significant_move_3'] = (abs(features_df['future_return_3']) > threshold / df_tech['close']).astype(
            int)
        features_df['significant_move_5'] = (abs(features_df['future_return_5']) > threshold / df_tech['close']).astype(
            int)

        # æ–¹å‘ç›®æ ‡
        features_df['direction_3'] = np.where(features_df['future_return_3'] > 0, 1,
                                              np.where(features_df['future_return_3'] < 0, -1, 0))
        features_df['direction_5'] = np.where(features_df['future_return_5'] > 0, 1,
                                              np.where(features_df['future_return_5'] < 0, -1, 0))

        return features_df

    def _bars_since_last_event(self, condition_series: pd.Series) -> pd.Series:
        """
        è®¡ç®—è·ç¦»ä¸Šæ¬¡äº‹ä»¶çš„Kçº¿æ•°ï¼ˆå‘é‡åŒ–ï¼‰ã€‚
        - äº‹ä»¶ï¼šcondition_series ä¸º True çš„ä½ç½®
        - äº‹ä»¶ä¹‹å‰ï¼šNaN
        - äº‹ä»¶ç‚¹ï¼š0
        - äº‹ä»¶ä¹‹åï¼šé€’å¢ 1,2,3...
        """
        n = len(condition_series)
        idx = condition_series.index
        # å°† NaN å½“ä½œ Falseï¼ˆè‹¥ä½ éœ€è¦ä¿æŒ NaN ç‰¹æ®Šå«ä¹‰ï¼Œå¯è‡ªè¡Œè°ƒæ•´ï¼‰
        ev = condition_series.fillna(False).to_numpy(dtype=bool)

        ar = np.arange(n, dtype=np.int64)
        # æŠŠäº‹ä»¶ä½ç½®è®¾ä¸ºè‡ªèº«ç´¢å¼•ï¼Œå¦åˆ™ä¸º -1ï¼›å†åšå‰ç¼€æœ€å¤§å€¼ï¼Œå¾—åˆ°â€œæœ€è¿‘ä¸€æ¬¡äº‹ä»¶çš„ç´¢å¼•â€
        last_idx = np.where(ev, ar, -1)
        last_idx = np.maximum.accumulate(last_idx)

        out = np.full(n, np.nan, dtype=float)
        m = last_idx != -1
        out[m] = ar[m] - last_idx[m]
        return pd.Series(out, index=idx, dtype=float)

    def _price_distance_to_last_peak(self, df_tech, peak_type):
        """
        çº¯NumPyå®ç°çš„ä»·æ ¼è·ç¦»è®¡ç®—ï¼ˆæœ€é«˜æ€§èƒ½ç‰ˆæœ¬ï¼‰
        """
        n = len(df_tech)
        idx = df_tech.index

        # è½¬æ¢ä¸ºNumPyæ•°ç»„
        is_peak = (df_tech['peak_type'] == peak_type).to_numpy()
        prices = df_tech['close'].to_numpy(dtype=float)

        # æ‰‹åŠ¨å®ç°forward fillï¼Œé¿å…åˆ›å»ºSeriesçš„å¼€é”€
        last_peak_prices = np.full(n, np.nan, dtype=float)
        current_peak = np.nan

        for i in range(n):
            if is_peak[i]:
                current_peak = prices[i]
            last_peak_prices[i] = current_peak

        # å‘é‡åŒ–è®¡ç®—
        result = np.full(n, np.nan, dtype=float)
        result[is_peak] = 0.0

        # è®¡ç®—éå³°å€¼ä½ç½®çš„è·ç¦»
        valid_mask = ~np.isnan(last_peak_prices) & ~is_peak
        result[valid_mask] = (prices[valid_mask] - last_peak_prices[valid_mask]) / last_peak_prices[valid_mask]

        return pd.Series(result, index=idx, dtype=float)


    # def _calculate_peak_trend(self, df_tech, window):
    #     """è®¡ç®—å³°å€¼è¶‹åŠ¿"""
    #     peak_prices = df_tech['close'].where(df_tech['is_peak'] == 1)
    #     return peak_prices.rolling(window=window, min_periods=2).apply(
    #         lambda x: np.polyfit(range(len(x.dropna())), x.dropna(), 1)[0] if len(x.dropna()) >= 2 else np.nan
    #     )

    def _calculate_peak_trend(self, df_tech, window):
        """
        çº¯å‘é‡åŒ–ç‰ˆæœ¬ï¼ˆé€‚åˆå³°å€¼å¯†é›†çš„åœºæ™¯ï¼‰
        é€šè¿‡é¢„å¤„ç†å³°å€¼åºåˆ—ï¼Œå‡å°‘NaNå¤„ç†å¼€é”€
        """
        idx = df_tech.index

        # 1. æå–æ‰€æœ‰å³°å€¼åŠå…¶ä½ç½®
        peak_mask = df_tech['is_peak'] == 1
        peak_positions = np.where(peak_mask)[0]
        peak_values = df_tech.loc[peak_mask, 'close'].values

        if len(peak_values) < 2:
            return pd.Series(np.nan, index=idx, dtype=float)

        # 2. ä¸ºæ¯ä¸ªå³°å€¼è®¡ç®—è¶‹åŠ¿ï¼ˆå‘å‰çœ‹windowä¸ªå³°å€¼ï¼‰
        result = np.full(len(df_tech), np.nan, dtype=float)

        for i in range(len(peak_positions)):
            current_pos = peak_positions[i]

            # è·å–å½“å‰åŠä¹‹å‰çš„å³°å€¼ï¼ˆæœ€å¤šwindowä¸ªï¼‰
            end_idx = i + 1
            start_idx = max(0, end_idx - window)

            if end_idx - start_idx >= 2:  # è‡³å°‘éœ€è¦2ä¸ªå³°å€¼
                # æå–ç›¸å…³å³°å€¼
                relevant_positions = peak_positions[start_idx:end_idx]
                relevant_values = peak_values[start_idx:end_idx]

                # è®¡ç®—æ–œç‡
                x = np.arange(len(relevant_values))
                slope = np.polyfit(x, relevant_values, 1)[0]

                # å°†ç»“æœèµ‹ç»™å½“å‰å³°å€¼ä½ç½®
                result[current_pos] = slope

        # 3. å‘å‰å¡«å……åˆ°æ‰€æœ‰ä½ç½®ï¼ˆå¯é€‰ï¼Œæ ¹æ®éœ€æ±‚å†³å®šï¼‰
        result_series = pd.Series(result, index=idx)
        # result_series = result_series.fillna(method='ffill')  # å¦‚æœéœ€è¦å¡«å……

        return result_series


    # def _calculate_momentum_divergence(self, df_tech, period):
    #     """è®¡ç®—åŠ¨é‡èƒŒç¦»"""
    #     price_trend = df_tech['close'].rolling(period).apply(lambda x: stats.linregress(range(len(x)), x)[0])
    #     rsi_trend = df_tech['rsi_14'].rolling(period).apply(lambda x: stats.linregress(range(len(x)), x)[0])
    #
    #     # èƒŒç¦»ä¿¡å·ï¼šä»·æ ¼å’ŒRSIè¶‹åŠ¿æ–¹å‘ç›¸å
    #     return np.where((price_trend > 0) & (rsi_trend < 0), 1,  # çœ‹è·ŒèƒŒç¦»
    #                     np.where((price_trend < 0) & (rsi_trend > 0), -1, 0))  # çœ‹æ¶¨èƒŒç¦»

    def _calculate_momentum_divergence(self, df_tech, period):
        """
        ä½¿ç”¨Pandasä¼˜åŒ–çš„ç‰ˆæœ¬ï¼ˆä¸­ç­‰æ€§èƒ½ï¼Œä»£ç ç®€æ´ï¼‰
        """

        # ä½¿ç”¨è‡ªå®šä¹‰çš„å¿«é€Ÿçº¿æ€§å›å½’å‡½æ•°
        def fast_linregress(x):
            """å¿«é€Ÿçº¿æ€§å›å½’ï¼Œåªè¿”å›æ–œç‡"""
            if len(x) < 2:
                return np.nan
            n = len(x)
            x_coords = np.arange(n)
            sum_x = np.sum(x_coords)
            sum_y = np.sum(x)
            sum_xy = np.sum(x_coords * x)
            sum_x2 = np.sum(x_coords * x_coords)

            denominator = n * sum_x2 - sum_x * sum_x
            if abs(denominator) < 1e-12:
                return np.nan

            return (n * sum_xy - sum_x * sum_y) / denominator

        # è®¡ç®—è¶‹åŠ¿
        price_trend = df_tech['close'].rolling(period).apply(fast_linregress, raw=True)
        rsi_trend = df_tech['rsi_14'].rolling(period).apply(fast_linregress, raw=True)

        # èƒŒç¦»ä¿¡å·ï¼šä»·æ ¼å’ŒRSIè¶‹åŠ¿æ–¹å‘ç›¸å
        return np.where((price_trend > 0) & (rsi_trend < 0), 1,  # çœ‹è·ŒèƒŒç¦»
                        np.where((price_trend < 0) & (rsi_trend > 0), -1, 0))  # çœ‹æ¶¨èƒŒç¦»

    def _identify_volatility_regime(self, df_tech):
        """è¯†åˆ«æ³¢åŠ¨ç‡çŠ¶æ€"""
        vol_percentile = df_tech['atr_14'].rolling(50).rank(pct=True)
        return np.where(vol_percentile > 0.8, 2,  # é«˜æ³¢åŠ¨
                        np.where(vol_percentile < 0.2, 0, 1))  # ä½æ³¢åŠ¨, ä¸­ç­‰æ³¢åŠ¨

    def _calculate_rsi_divergence(self, df_tech):
        """è®¡ç®—RSIèƒŒç¦»"""
        return self._calculate_momentum_divergence(df_tech, 14)

    def _detect_signal_cross(self, series1, series2):
        """æ£€æµ‹ä¿¡å·äº¤å‰"""
        cross_up = ((series1 > series2) & (series1.shift(1) <= series2.shift(1))).astype(int)
        cross_down = ((series1 < series2) & (series1.shift(1) >= series2.shift(1))).astype(int)
        return cross_up - cross_down

    def _detect_histogram_peaks(self, hist_series):
        """æ£€æµ‹MACDæŸ±çŠ¶å›¾å³°å€¼"""
        peaks = (hist_series > hist_series.shift(1)) & (hist_series > hist_series.shift(-1))
        troughs = (hist_series < hist_series.shift(1)) & (hist_series < hist_series.shift(-1))
        return peaks.astype(int) - troughs.astype(int)

    def _detect_support_resistance_break(self, df_tech, sr_type):
        """æ£€æµ‹æ”¯æ’‘é˜»åŠ›çªç ´"""
        if sr_type == 'resistance':
            resistance = df_tech['high'].rolling(20).max()
            return (df_tech['close'] > resistance.shift(1)).astype(int)
        else:
            support = df_tech['low'].rolling(20).min()
            return (df_tech['close'] < support.shift(1)).astype(int)

    def _calculate_trend_strength(self, df_tech):
        """è®¡ç®—è¶‹åŠ¿å¼ºåº¦"""
        adx = talib.ADX(df_tech['high'], df_tech['low'], df_tech['close'], timeperiod=14)
        return adx / 100  # æ ‡å‡†åŒ–åˆ°0-1

    def _identify_market_regime(self, df_tech):
        """è¯†åˆ«å¸‚åœºçŠ¶æ€"""
        sma_20 = df_tech['sma_20']
        sma_50 = df_tech['sma_50'] if 'sma_50' in df_tech.columns else df_tech['sma_20']

        return np.where(sma_20 > sma_50, 1,  # ç‰›å¸‚
                        np.where(sma_20 < sma_50, -1, 0))  # ç†Šå¸‚, éœ‡è¡

    def _identify_hammer_pattern(self, df_tech):
        """è¯†åˆ«é”¤å­çº¿å½¢æ€"""
        body_size = abs(df_tech['close'] - df_tech['open'])
        lower_shadow = df_tech['open'].combine(df_tech['close'], min) - df_tech['low']
        upper_shadow = df_tech['high'] - df_tech['open'].combine(df_tech['close'], max)

        return ((lower_shadow > 2 * body_size) & (upper_shadow < body_size)).astype(int)

    def _identify_engulfing_pattern(self, df_tech):
        """è¯†åˆ«åæ²¡å½¢æ€"""
        prev_body = abs(df_tech['close'].shift(1) - df_tech['open'].shift(1))
        curr_body = abs(df_tech['close'] - df_tech['open'])

        bullish_engulf = ((df_tech['close'] > df_tech['open']) &
                          (df_tech['close'].shift(1) < df_tech['open'].shift(1)) &
                          (curr_body > prev_body)).astype(int)

        bearish_engulf = ((df_tech['close'] < df_tech['open']) &
                          (df_tech['close'].shift(1) > df_tech['open'].shift(1)) &
                          (curr_body > prev_body)).astype(int)

        return bullish_engulf - bearish_engulf

    def _calculate_price_efficiency(self, price_series, period):
        """è®¡ç®—ä»·æ ¼æ•ˆç‡"""
        price_change = abs(price_series.diff(period))
        path_length = abs(price_series.diff()).rolling(period).sum()
        return price_change / (path_length + 1e-8)


class TradingSignalGenerator:
    """
    äº¤æ˜“ä¿¡å·ç”Ÿæˆå™¨ - åŸºäºæœºå™¨å­¦ä¹ çš„åå°”è¡—çº§äº¤æ˜“ç³»ç»Ÿ
    """

    def __init__(self):
        self.feature_engineer = PeakFeatureEngineer()
        self.models = {}
        self.scalers = {}
        self.is_trained = False

    def prepare_training_data(self, df: pd.DataFrame, peaks_results: dict):
        """å‡†å¤‡è®­ç»ƒæ•°æ®"""
        features_df = self.feature_engineer.extract_comprehensive_features(df, peaks_results)

        # åˆ†ç¦»ç‰¹å¾å’Œç›®æ ‡
        target_cols = [col for col in features_df.columns if col.startswith(('future_', 'significant_', 'direction_'))]
        feature_cols = [col for col in features_df.columns if col not in target_cols]

        X = features_df[feature_cols].copy()
        y_dict = {col: features_df[col].copy() for col in target_cols}

        print(f"ğŸ“Š ç‰¹å¾çŸ©é˜µå½¢çŠ¶: {X.shape}")
        print(f"ğŸ¯ ç›®æ ‡å˜é‡æ•°é‡: {len(y_dict)}")
        print(f"ğŸ” ç‰¹å¾æ•°é‡: {len(feature_cols)}")

        return X, y_dict, feature_cols

    def train_models(self, X: pd.DataFrame, y_dict: dict, feature_cols: list):
        """è®­ç»ƒå¤šä¸ªé¢„æµ‹æ¨¡å‹"""
        print("ğŸš€ å¼€å§‹è®­ç»ƒæœºå™¨å­¦ä¹ æ¨¡å‹...")

        # æ•°æ®é¢„å¤„ç†
        scaler = RobustScaler()  # å¯¹å¼‚å¸¸å€¼æ›´é²æ£’
        X_scaled = pd.DataFrame(
            scaler.fit_transform(X.fillna(0)),
            columns=X.columns,
            index=X.index
        )
        self.scalers['features'] = scaler

        # æ—¶é—´åºåˆ—åˆ†å‰²
        tscv = TimeSeriesSplit(n_splits=5)

        # è®­ç»ƒä¸åŒç±»å‹çš„æ¨¡å‹
        self.models = {}

        # 1. å›å½’æ¨¡å‹ - é¢„æµ‹æ”¶ç›Šç‡
        print("ğŸ“ˆ è®­ç»ƒæ”¶ç›Šç‡å›å½’æ¨¡å‹...")
        for target in ['future_return_3', 'future_return_5']:
            if target in y_dict:
                y_clean = y_dict[target].fillna(0)

                # æ¢¯åº¦æå‡å›å½’
                gb_regressor = GradientBoostingRegressor(
                    n_estimators=200,
                    learning_rate=0.1,
                    max_depth=6,
                    random_state=42,
                    subsample=0.8
                )

                # äº¤å‰éªŒè¯è¯„åˆ†
                cv_scores = cross_val_score(gb_regressor, X_scaled, y_clean, cv=tscv, scoring='neg_mean_squared_error')
                print(f"  {target} - CV MSE: {-cv_scores.mean():.6f} Â± {cv_scores.std():.6f}")

                # è®­ç»ƒæœ€ç»ˆæ¨¡å‹
                gb_regressor.fit(X_scaled, y_clean)
                self.models[target] = gb_regressor

        # 2. åˆ†ç±»æ¨¡å‹ - é¢„æµ‹æ–¹å‘å’Œæ˜¾è‘—æ€§
        print("ğŸ¯ è®­ç»ƒåˆ†ç±»æ¨¡å‹...")
        for target in ['direction_3', 'direction_5', 'significant_move_3', 'significant_move_5']:
            if target in y_dict:
                y_clean = y_dict[target].fillna(0)

                # éšæœºæ£®æ—åˆ†ç±»å™¨
                rf_classifier = RandomForestClassifier(
                    n_estimators=300,
                    max_depth=8,
                    min_samples_split=10,
                    min_samples_leaf=5,
                    random_state=42,
                    class_weight='balanced'
                )

                # äº¤å‰éªŒè¯
                cv_scores = cross_val_score(rf_classifier, X_scaled, y_clean, cv=tscv, scoring='accuracy')
                print(f"  {target} - CV Accuracy: {cv_scores.mean():.4f} Â± {cv_scores.std():.4f}")

                # è®­ç»ƒæœ€ç»ˆæ¨¡å‹
                rf_classifier.fit(X_scaled, y_clean)
                self.models[target] = rf_classifier

        self.is_trained = True
        self.feature_cols = feature_cols
        print("âœ… æ¨¡å‹è®­ç»ƒå®Œæˆ!")

        return self.models

    def generate_trading_signals(self, df: pd.DataFrame, peaks_results: dict) -> pd.DataFrame:
        """ç”Ÿæˆäº¤æ˜“ä¿¡å·"""
        if not self.is_trained:
            raise ValueError("æ¨¡å‹å°šæœªè®­ç»ƒï¼Œè¯·å…ˆè°ƒç”¨ train_models()")

        print("ğŸ”® ç”Ÿæˆäº¤æ˜“ä¿¡å·...")

        # æå–ç‰¹å¾
        features_df = self.feature_engineer.extract_comprehensive_features(df, peaks_results)
        X = features_df[self.feature_cols].copy()

        # æ•°æ®é¢„å¤„ç†
        X_scaled = pd.DataFrame(
            self.scalers['features'].transform(X.fillna(0)),
            columns=X.columns,
            index=X.index
        )

        # ç”Ÿæˆé¢„æµ‹
        signals_df = pd.DataFrame(index=df.index)
        signals_df['timestamp'] = df.index
        signals_df['close_price'] = df['close']

        # å›å½’é¢„æµ‹ - é¢„æœŸæ”¶ç›Šç‡
        for target in ['future_return_3', 'future_return_5']:
            if target in self.models:
                predictions = self.models[target].predict(X_scaled)
                signals_df[f'predicted_{target}'] = predictions

        # åˆ†ç±»é¢„æµ‹ - æ–¹å‘å’Œæ¦‚ç‡
        for target in ['direction_3', 'direction_5', 'significant_move_3', 'significant_move_5']:
            if target in self.models:
                predictions = self.models[target].predict(X_scaled)
                probabilities = self.models[target].predict_proba(X_scaled)

                signals_df[f'predicted_{target}'] = predictions

                # è·å–æœ€é«˜æ¦‚ç‡
                max_prob = np.max(probabilities, axis=1)
                signals_df[f'{target}_confidence'] = max_prob

        # ç”Ÿæˆç»¼åˆäº¤æ˜“ä¿¡å·
        signals_df = self._generate_composite_signals(signals_df)

        return signals_df

    def _generate_composite_signals(self, signals_df: pd.DataFrame) -> pd.DataFrame:
        """ç”Ÿæˆç»¼åˆäº¤æ˜“ä¿¡å·"""

        # 1. å¼ºåº¦è¯„åˆ†ç³»ç»Ÿ
        signals_df['bull_strength'] = 0.0
        signals_df['bear_strength'] = 0.0

        # åŸºäºæ”¶ç›Šç‡é¢„æµ‹çš„å¼ºåº¦
        if 'predicted_future_return_3' in signals_df.columns:
            signals_df['bull_strength'] += np.clip(signals_df['predicted_future_return_3'] * 100, 0, 5)
            signals_df['bear_strength'] += np.clip(-signals_df['predicted_future_return_3'] * 100, 0, 5)

        if 'predicted_future_return_5' in signals_df.columns:
            signals_df['bull_strength'] += np.clip(signals_df['predicted_future_return_5'] * 100, 0, 3)
            signals_df['bear_strength'] += np.clip(-signals_df['predicted_future_return_5'] * 100, 0, 3)

        # åŸºäºæ–¹å‘é¢„æµ‹çš„å¼ºåº¦
        if 'predicted_direction_3' in signals_df.columns and 'direction_3_confidence' in signals_df.columns:
            direction_strength = signals_df['direction_3_confidence'] * 3
            signals_df['bull_strength'] += np.where(signals_df['predicted_direction_3'] == 1, direction_strength, 0)
            signals_df['bear_strength'] += np.where(signals_df['predicted_direction_3'] == -1, direction_strength, 0)

        # åŸºäºæ˜¾è‘—æ€§é¢„æµ‹çš„å¼ºåº¦
        if 'significant_move_3_confidence' in signals_df.columns:
            signals_df['bull_strength'] += signals_df['significant_move_3_confidence'] * 2
            signals_df['bear_strength'] += signals_df['significant_move_3_confidence'] * 2

        # 2. ä¿¡å·ç­‰çº§åˆ†ç±»
        total_strength = signals_df['bull_strength'] + signals_df['bear_strength']
        net_strength = signals_df['bull_strength'] - signals_df['bear_strength']

        # ä¿¡å·å¼ºåº¦ç­‰çº§ (0-10åˆ†)
        signals_df['signal_strength'] = np.clip(total_strength, 0, 10)

        # ä¿¡å·æ–¹å‘ (-1, 0, 1)
        signals_df['signal_direction'] = np.where(
            net_strength > 1, 1,  # çœ‹æ¶¨
            np.where(net_strength < -1, -1, 0)  # çœ‹è·Œ, ä¸­æ€§
        )

        # 3. äº¤æ˜“ä¿¡å·ç­‰çº§
        def categorize_signal(row):
            strength = row['signal_strength']
            direction = row['signal_direction']

            if strength >= 7:
                return f"STRONG_{'BUY' if direction > 0 else 'SELL' if direction < 0 else 'HOLD'}"
            elif strength >= 5:
                return f"MODERATE_{'BUY' if direction > 0 else 'SELL' if direction < 0 else 'HOLD'}"
            elif strength >= 3:
                return f"WEAK_{'BUY' if direction > 0 else 'SELL' if direction < 0 else 'HOLD'}"
            else:
                return "NO_SIGNAL"

        signals_df['trading_signal'] = signals_df.apply(categorize_signal, axis=1)

        # 4. é£é™©è°ƒæ•´åçš„ä»“ä½å»ºè®®
        signals_df['position_size'] = self._calculate_position_size(signals_df)

        # 5. æ­¢æŸæ­¢ç›ˆå»ºè®®
        signals_df = self._calculate_stop_take_levels(signals_df)

        return signals_df

    def _calculate_position_size(self, signals_df: pd.DataFrame) -> pd.Series:
        """è®¡ç®—å»ºè®®ä»“ä½å¤§å° (0-1ä¹‹é—´)"""
        base_size = signals_df['signal_strength'] / 10 * 0.3  # åŸºç¡€ä»“ä½æœ€å¤§30%

        # ä¿¡å·ç½®ä¿¡åº¦è°ƒæ•´
        confidence_avg = (
                                 signals_df.get('direction_3_confidence', 0.5) +
                                 signals_df.get('significant_move_3_confidence', 0.5)
                         ) / 2

        adjusted_size = base_size * confidence_avg

        return np.clip(adjusted_size, 0, 0.5)  # æœ€å¤§50%ä»“ä½

    def _calculate_stop_take_levels(self, signals_df: pd.DataFrame) -> pd.DataFrame:
        """è®¡ç®—æ­¢æŸæ­¢ç›ˆæ°´å¹³"""

        # åŸºäºé¢„æœŸæ”¶ç›Šç‡çš„æ­¢ç›ˆ
        expected_return_3 = signals_df.get('predicted_future_return_3', 0)
        expected_return_5 = signals_df.get('predicted_future_return_5', 0)

        # åŠ¨æ€æ­¢ç›ˆ (é¢„æœŸæ”¶ç›Šçš„80%)
        signals_df['take_profit_pct'] = np.clip(
            np.maximum(abs(expected_return_3), abs(expected_return_5)) * 0.8,
            0.005,  # æœ€å°0.5%
            0.05  # æœ€å¤§5%
        )

        # åŠ¨æ€æ­¢æŸ (é¢„æœŸæ”¶ç›Šçš„40%ï¼Œä½†æœ€å¤§2%)
        signals_df['stop_loss_pct'] = np.clip(
            signals_df['take_profit_pct'] * 0.4,
            0.003,  # æœ€å°0.3%
            0.02  # æœ€å¤§2%
        )

        # è®¡ç®—å…·ä½“ä»·ä½
        current_price = signals_df['close_price']

        signals_df['take_profit_long'] = current_price * (1 + signals_df['take_profit_pct'])
        signals_df['stop_loss_long'] = current_price * (1 - signals_df['stop_loss_pct'])

        signals_df['take_profit_short'] = current_price * (1 - signals_df['take_profit_pct'])
        signals_df['stop_loss_short'] = current_price * (1 + signals_df['stop_loss_pct'])

        return signals_df

    def analyze_feature_importance(self) -> dict:
        """åˆ†æç‰¹å¾é‡è¦æ€§"""
        if not self.is_trained:
            return {}

        importance_dict = {}

        for model_name, model in self.models.items():
            if hasattr(model, 'feature_importances_'):
                # è·å–ç‰¹å¾é‡è¦æ€§
                importances = model.feature_importances_
                feature_importance = pd.DataFrame({
                    'feature': self.feature_cols,
                    'importance': importances
                }).sort_values('importance', ascending=False)

                importance_dict[model_name] = feature_importance.head(20)

                print(f"\nğŸ” {model_name} - Top 10 é‡è¦ç‰¹å¾:")
                for idx, row in feature_importance.head(10).iterrows():
                    print(f"  {row['feature']}: {row['importance']:.4f}")

        return importance_dict

    def backtest_signals(self, signals_df: pd.DataFrame) -> dict:
        """å›æµ‹äº¤æ˜“ä¿¡å·"""
        print("ğŸ“Š æ‰§è¡Œä¿¡å·å›æµ‹...")

        # ç®€å•å›æµ‹é€»è¾‘
        results = {
            'total_signals': 0,
            'buy_signals': 0,
            'sell_signals': 0,
            'strong_signals': 0,
            'win_rate': 0.0,
            'avg_return_per_signal': 0.0
        }

        # ç»Ÿè®¡ä¿¡å·åˆ†å¸ƒ
        results['total_signals'] = len(signals_df[signals_df['trading_signal'] != 'NO_SIGNAL'])
        results['buy_signals'] = len(signals_df[signals_df['signal_direction'] == 1])
        results['sell_signals'] = len(signals_df[signals_df['signal_direction'] == -1])
        results['strong_signals'] = len(signals_df[signals_df['signal_strength'] >= 7])

        # è®¡ç®—ä¿¡å·å‡†ç¡®ç‡ (ç®€åŒ–ç‰ˆ)
        if 'predicted_future_return_3' in signals_df.columns:
            predicted_returns = signals_df['predicted_future_return_3'].fillna(0)
            signal_directions = signals_df['signal_direction'].fillna(0)

            # è®¡ç®—æ–¹å‘å‡†ç¡®ç‡
            correct_predictions = ((predicted_returns > 0) & (signal_directions > 0)) | \
                                  ((predicted_returns < 0) & (signal_directions < 0))

            valid_predictions = signal_directions != 0
            if valid_predictions.sum() > 0:
                results['win_rate'] = correct_predictions[valid_predictions].mean()
                results['avg_return_per_signal'] = abs(predicted_returns[valid_predictions]).mean()

        print(f"ğŸ“ˆ å›æµ‹ç»“æœ:")
        print(f"  æ€»ä¿¡å·æ•°: {results['total_signals']}")
        print(f"  ä¹°å…¥ä¿¡å·: {results['buy_signals']}")
        print(f"  å–å‡ºä¿¡å·: {results['sell_signals']}")
        print(f"  å¼ºä¿¡å·æ•°: {results['strong_signals']}")
        print(f"  èƒœç‡: {results['win_rate']:.2%}")
        print(f"  å¹³å‡é¢„æœŸæ”¶ç›Š: {results['avg_return_per_signal']:.4%}")

        return results


# å®Œæ•´ä½¿ç”¨ç¤ºä¾‹
def run_complete_trading_system(data_file_path: str, peak_file_path: str):
    """è¿è¡Œå®Œæ•´çš„äº¤æ˜“ä¿¡å·ç³»ç»Ÿ"""
    df = load_process_data(data_file_path)
    peak_file_absolute_path = Path(build_data_dir() / peak_file_path)
    if not peak_file_absolute_path.exists():
        logBot.critical("Load peak data file not exist")
        return
    with Path(peak_file_absolute_path).open("r", encoding="utf-8") as f:
        peaks_results = json.load(f, object_hook=restore_hook)
    logBot.info("Load peak data Finish")
    signal_generator = TradingSignalGenerator()

    # 3. å‡†å¤‡è®­ç»ƒæ•°æ®
    X, y_dict, feature_cols = signal_generator.prepare_training_data(df, peaks_results)

    # 4. è®­ç»ƒæ¨¡å‹
    models = signal_generator.train_models(X, y_dict, feature_cols)

    # 5. ç”Ÿæˆäº¤æ˜“ä¿¡å·
    signals_df = signal_generator.generate_trading_signals(df, peaks_results)

    # 6. åˆ†æç‰¹å¾é‡è¦æ€§
    feature_importance = signal_generator.analyze_feature_importance()

    # 7. å›æµ‹ä¿¡å·
    backtest_results = signal_generator.backtest_signals(signals_df)

    # 8. è¾“å‡ºæœ€æ–°ä¿¡å·
    print("\nğŸ¯ æœ€æ–°äº¤æ˜“ä¿¡å· (æœ€è¿‘10æ¡):")
    latest_signals = signals_df.tail(10)[
        ['timestamp', 'close_price', 'trading_signal', 'signal_strength',
         'position_size', 'take_profit_pct', 'stop_loss_pct']
    ]

    for idx, row in latest_signals.iterrows():
        print(f"  {row['timestamp']}: {row['trading_signal']} | "
              f"å¼ºåº¦: {row['signal_strength']:.1f} | "
              f"ä»“ä½: {row['position_size']:.2%} | "
              f"æ­¢ç›ˆ: {row['take_profit_pct']:.2%} | "
              f"æ­¢æŸ: {row['stop_loss_pct']:.2%}")

    return {
        'signals': signals_df,
        'models': models,
        'feature_importance': feature_importance,
        'backtest_results': backtest_results
    }


if __name__ == "__main__":
    data_file = "BTC_USDT_USDT-5m-futures.csv"
    peak_file = "peak_report_1756866531.json"

    try:
        results = run_complete_trading_system(data_file, peak_file)

        # ä¿å­˜ç»“æœ
        results['signals'].to_csv('btc_trading_signals.csv', index=False)
        print("ğŸ’¾ äº¤æ˜“ä¿¡å·å·²ä¿å­˜è‡³ btc_trading_signals.csv")

    except Exception as e:
        print(f"âŒ ç³»ç»Ÿè¿è¡Œå¤±è´¥: {e}")
        print("è¯·ç¡®ä¿æ•°æ®æ–‡ä»¶æ ¼å¼æ­£ç¡®ï¼Œå¹¶å·²å¯¼å…¥å¿…è¦çš„ä¾èµ–æ¨¡å—")