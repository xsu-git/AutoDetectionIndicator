#!/usr/bin/env python
# -*- coding: utf-8 -*-
'''
@Time              @Author    @Version    @Desciption
---------------    -------    --------    -----------
2025/9/9 11:16     Xsu         1.0         None
'''

# !/usr/bin/env python
# -*- coding: utf-8 -*-
"""
ä¼˜åŒ–åçš„ä¸»æ‰§è¡Œæ–‡ä»¶
å®ç°æ›´çµæ´»çš„ä¿¡å·ç”Ÿæˆå’Œå›æµ‹
"""
from process.loader import load_process_data, load_peak_data
from process.feature_detection import FeatureExtractorLoader
from utils.data_preprocess_util import feather_to_csv
from process.model_train import MachineLearnTrain as EnhancedSignalGenerator
from process.backtester import EnhancedBacktester
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.model_selection import TimeSeriesSplit, cross_val_score
from sklearn.ensemble import RandomForestClassifier, GradientBoostingRegressor
from sklearn.preprocessing import RobustScaler
import warnings

warnings.filterwarnings('ignore')


class OptimizedTradingSystem:
    """ä¼˜åŒ–åçš„äº¤æ˜“ç³»ç»Ÿ"""

    def __init__(self):
        self.signal_generator = None
        self.backtester = None
        self.features_df = None
        self.df_tech = None

    def run_optimized_strategy(self, data_file: str, peak_file: str):
        """æ‰§è¡Œä¼˜åŒ–ç­–ç•¥"""

        print("=" * 80)
        print("ğŸš€ å¯åŠ¨ä¼˜åŒ–åçš„é‡åŒ–äº¤æ˜“ç³»ç»Ÿ")
        print("=" * 80)

        # 1. æ•°æ®åŠ è½½
        print("\nğŸ“Š åŠ è½½æ•°æ®...")
        self.df_tech = load_process_data(data_file)
        peak_tech = load_peak_data(peak_file)

        # 2. ç‰¹å¾æå–
        print("\nğŸ”§ æå–ç‰¹å¾...")
        self.features_df = FeatureExtractorLoader(
            self.df_tech, peak_tech
        ).extract_all_features(exclude=["PeakStructureFeature"])

        # 3. å‡†å¤‡è®­ç»ƒæ•°æ®
        target_cols = [col for col in self.features_df.columns
                       if col.startswith(('future_', 'significant_', 'direction_'))]
        feature_cols = [col for col in self.features_df.columns
                        if col not in target_cols]

        X = self.features_df[feature_cols].copy()
        y_dict = {col: self.features_df[col].copy() for col in target_cols}

        print(f"\nğŸ“Š æ•°æ®ç»´åº¦:")
        print(f"  - ç‰¹å¾çŸ©é˜µ: {X.shape}")
        print(f"  - ç›®æ ‡å˜é‡: {len(y_dict)}")
        print(f"  - ç‰¹å¾æ•°é‡: {len(feature_cols)}")

        # 4. è®­ç»ƒå¢å¼ºæ¨¡å‹
        print("\nğŸ¤– è®­ç»ƒå¢å¼ºæ¨¡å‹...")
        self.signal_generator = self._train_enhanced_models(X, y_dict, feature_cols)

        # 5. ç”Ÿæˆäº¤æ˜“ä¿¡å·
        print("\nğŸ“¡ ç”Ÿæˆäº¤æ˜“ä¿¡å·...")
        signals_df = self.signal_generator.generate_trading_signals(
            self.df_tech, self.features_df
        )

        # 6. ä¿¡å·ç»Ÿè®¡
        self._analyze_signals(signals_df)

        # 7. æ‰§è¡Œå›æµ‹
        print("\nğŸ“ˆ æ‰§è¡Œå¢å¼ºå›æµ‹...")
        self.backtester = EnhancedBacktester(
            initial_capital=100000,
            commission=0.001,
            slippage=0.0005,
            max_positions=5
        )

        backtest_results = self.backtester.backtest(signals_df, self.df_tech)

        # 8. è¾“å‡ºç»“æœ
        self._print_results(backtest_results)

        # 9. å¯è§†åŒ–
        self._visualize_results(backtest_results, signals_df)

        return backtest_results

    def _train_enhanced_models(self, X, y_dict, feature_cols):
        """è®­ç»ƒå¢å¼ºæ¨¡å‹"""

        generator = EnhancedSignalGenerator()

        # æ•°æ®é¢„å¤„ç†
        scaler = RobustScaler()
        X_scaled = pd.DataFrame(
            scaler.fit_transform(X.fillna(0)),
            columns=X.columns,
            index=X.index
        )
        generator.scalers['features'] = scaler
        generator.feature_cols = feature_cols

        # æ—¶é—´åºåˆ—äº¤å‰éªŒè¯
        tscv = TimeSeriesSplit(n_splits=5)

        # è®­ç»ƒå›å½’æ¨¡å‹ï¼ˆé¢„æµ‹æ”¶ç›Šç‡ï¼‰
        for target in ['future_return_3', 'future_return_5']:
            if target in y_dict:
                y_clean = y_dict[target].fillna(0)

                # ä½¿ç”¨æ¢¯åº¦æå‡å›å½’
                model = GradientBoostingRegressor(
                    n_estimators=150,  # å‡å°‘è¿‡æ‹Ÿåˆ
                    learning_rate=0.05,  # æ›´ä¿å®ˆçš„å­¦ä¹ ç‡
                    max_depth=5,
                    min_samples_split=20,
                    min_samples_leaf=10,
                    subsample=0.7,
                    random_state=42
                )

                # äº¤å‰éªŒè¯
                cv_scores = cross_val_score(
                    model, X_scaled, y_clean,
                    cv=tscv, scoring='neg_mean_squared_error'
                )
                print(f"  {target} - CV MSE: {-cv_scores.mean():.6f}")

                model.fit(X_scaled, y_clean)
                generator.models[target] = model

        # è®­ç»ƒåˆ†ç±»æ¨¡å‹ï¼ˆé¢„æµ‹æ–¹å‘ï¼‰
        for target in ['direction_3', 'direction_5', 'significant_move_3', 'significant_move_5']:
            if target in y_dict:
                y_clean = y_dict[target].fillna(0)

                # ä½¿ç”¨éšæœºæ£®æ—
                model = RandomForestClassifier(
                    n_estimators=200,
                    max_depth=6,
                    min_samples_split=15,
                    min_samples_leaf=8,
                    max_features='sqrt',
                    random_state=42,
                    class_weight='balanced'
                )

                # äº¤å‰éªŒè¯
                cv_scores = cross_val_score(
                    model, X_scaled, y_clean,
                    cv=tscv, scoring='accuracy'
                )
                print(f"  {target} - CV Accuracy: {cv_scores.mean():.4f}")

                model.fit(X_scaled, y_clean)
                generator.models[target] = model

        generator.is_trained = True
        return generator

    def _analyze_signals(self, signals_df):
        """åˆ†æä¿¡å·åˆ†å¸ƒ"""
        print("\nğŸ“Š ä¿¡å·åˆ†å¸ƒåˆ†æ:")

        signal_counts = signals_df['trading_signal'].value_counts()

        for signal, count in signal_counts.items():
            if signal != 'NO_SIGNAL':
                percentage = count / len(signals_df) * 100
                print(f"  {signal}: {count} ({percentage:.2f}%)")

        # ç»Ÿè®¡ä¹°å–ä¿¡å·
        buy_signals = signals_df[signals_df['trading_signal'].str.contains('BUY', na=False)]
        sell_signals = signals_df[signals_df['trading_signal'].str.contains('SELL', na=False)]

        print(f"\n  æ€»ä¹°å…¥ä¿¡å·: {len(buy_signals)}")
        print(f"  æ€»å–å‡ºä¿¡å·: {len(sell_signals)}")
        print(f"  ä¿¡å·è¦†ç›–ç‡: {(len(buy_signals) + len(sell_signals)) / len(signals_df) * 100:.2f}%")

    def _print_results(self, results):
        """æ‰“å°å›æµ‹ç»“æœ"""
        metrics = results['metrics']

        print("\n" + "=" * 80)
        print("ğŸ“Š å›æµ‹ç»“æœæ±‡æ€»")
        print("=" * 80)

        print("\nğŸ’° æ”¶ç›ŠæŒ‡æ ‡:")
        print(f"  æ€»æ”¶ç›Šç‡: {metrics['total_return']:.2%}")
        print(f"  å¹´åŒ–æ”¶ç›Šç‡: {metrics.get('annualized_return', 0):.2%}")
        print(f"  åˆ©æ¶¦å› å­: {metrics.get('profit_factor', 0):.2f}")

        print("\nğŸ“ˆ äº¤æ˜“ç»Ÿè®¡:")
        print(f"  æ€»äº¤æ˜“æ¬¡æ•°: {metrics['total_trades']}")
        print(f"  èƒœç‡: {metrics['win_rate']:.2%}")
        print(f"  å¹³å‡ç›ˆåˆ©: ${metrics.get('avg_win', 0):.2f}")
        print(f"  å¹³å‡äºæŸ: ${metrics.get('avg_loss', 0):.2f}")
        print(f"  å¹³å‡æŒä»“æ—¶é—´: {metrics.get('avg_holding_period', 0):.1f} å°æ—¶")

        print("\nâš ï¸ é£é™©æŒ‡æ ‡:")
        print(f"  å¤æ™®æ¯”ç‡: {metrics['sharpe_ratio']:.3f}")
        print(f"  æœ€å¤§å›æ’¤: {metrics['max_drawdown']:.2%}")
        print(f"  Calmaræ¯”ç‡: {metrics.get('calmar_ratio', 0):.3f}")

        print("\nğŸ¯ ä¿¡å·ç±»å‹ç»Ÿè®¡:")
        for signal_type, stats in metrics.get('signal_statistics', {}).items():
            print(f"\n  {signal_type}:")
            print(f"    äº¤æ˜“æ¬¡æ•°: {stats['count']}")
            print(f"    èƒœç‡: {stats['win_rate']:.2%}")
            print(f"    å¹³å‡æ”¶ç›Š: {stats['avg_return']:.4%}")
            print(f"    æ€»ç›ˆäº: ${stats['total_pnl']:.2f}")

    def _visualize_results(self, results, signals_df):
        """å¯è§†åŒ–ç»“æœ"""

        equity_df = pd.DataFrame(results['equity_curve'])

        fig, axes = plt.subplots(3, 2, figsize=(15, 12))

        # 1. æƒç›Šæ›²çº¿
        ax1 = axes[0, 0]
        ax1.plot(equity_df.index, equity_df['total_value'], 'b-', linewidth=2)
        ax1.fill_between(equity_df.index, self.backtester.initial_capital,
                         equity_df['total_value'], alpha=0.3)
        ax1.set_title('æƒç›Šæ›²çº¿', fontsize=12, fontweight='bold')
        ax1.set_ylabel('æ€»èµ„äº§ ($)')
        ax1.grid(True, alpha=0.3)
        ax1.axhline(y=self.backtester.initial_capital, color='r',
                    linestyle='--', alpha=0.5, label='åˆå§‹èµ„é‡‘')

        # 2. å›æ’¤æ›²çº¿
        ax2 = axes[0, 1]
        cummax = equity_df['total_value'].cummax()
        drawdown = (equity_df['total_value'] - cummax) / cummax * 100
        ax2.fill_between(equity_df.index, 0, drawdown, color='red', alpha=0.5)
        ax2.set_title('å›æ’¤æ›²çº¿', fontsize=12, fontweight='bold')
        ax2.set_ylabel('å›æ’¤ (%)')
        ax2.grid(True, alpha=0.3)

        # 3. æŒä»“æ•°é‡
        ax3 = axes[1, 0]
        ax3.plot(equity_df.index, equity_df['num_positions'], 'g-', linewidth=1)
        ax3.fill_between(equity_df.index, 0, equity_df['num_positions'],
                         color='green', alpha=0.3)
        ax3.set_title('æŒä»“æ•°é‡', fontsize=12, fontweight='bold')
        ax3.set_ylabel('æŒä»“æ•°')
        ax3.grid(True, alpha=0.3)

        # 4. ä¿¡å·åˆ†å¸ƒ
        ax4 = axes[1, 1]
        signal_types = ['STRONG_BUY', 'MODERATE_BUY', 'WEAK_BUY',
                        'STRONG_SELL', 'MODERATE_SELL', 'WEAK_SELL']
        signal_counts = [len(signals_df[signals_df['trading_signal'] == s])
                         for s in signal_types]
        colors = ['darkgreen', 'green', 'lightgreen',
                  'darkred', 'red', 'lightcoral']
        ax4.bar(range(len(signal_types)), signal_counts, color=colors)
        ax4.set_xticks(range(len(signal_types)))
        ax4.set_xticklabels([s.replace('_', '\n') for s in signal_types],
                            rotation=45, ha='right')
        ax4.set_title('ä¿¡å·ç±»å‹åˆ†å¸ƒ', fontsize=12, fontweight='bold')
        ax4.set_ylabel('ä¿¡å·æ•°é‡')
        ax4.grid(True, alpha=0.3, axis='y')

        # 5. æ”¶ç›Šåˆ†å¸ƒ
        ax5 = axes[2, 0]
        trades = [t for t in results['trades'] if 'return' in t]
        if trades:
            returns = [t['return'] * 100 for t in trades]
            ax5.hist(returns, bins=30, color='blue', alpha=0.6, edgecolor='black')
            ax5.axvline(x=0, color='red', linestyle='--', alpha=0.5)
            ax5.set_title('æ”¶ç›Šç‡åˆ†å¸ƒ', fontsize=12, fontweight='bold')
            ax5.set_xlabel('æ”¶ç›Šç‡ (%)')
            ax5.set_ylabel('é¢‘æ¬¡')
            ax5.grid(True, alpha=0.3)

        # 6. ç´¯è®¡æ”¶ç›Šå¯¹æ¯”
        ax6 = axes[2, 1]
        cumulative_return = (equity_df['total_value'] / self.backtester.initial_capital - 1) * 100
        benchmark_return = (self.df_tech['close'] / self.df_tech['close'].iloc[0] - 1) * 100

        ax6.plot(equity_df.index, cumulative_return, 'b-', linewidth=2, label='ç­–ç•¥')
        ax6.plot(self.df_tech.index[:len(benchmark_return)],
                 benchmark_return[:len(equity_df)], 'gray',
                 linewidth=1, alpha=0.7, label='ä¹°å…¥æŒæœ‰')
        ax6.set_title('ç´¯è®¡æ”¶ç›Šå¯¹æ¯”', fontsize=12, fontweight='bold')
        ax6.set_ylabel('ç´¯è®¡æ”¶ç›Šç‡ (%)')
        ax6.legend()
        ax6.grid(True, alpha=0.3)

        plt.tight_layout()
        plt.show()


if __name__ == '__main__':
    # æ‰§è¡Œä¼˜åŒ–ç­–ç•¥
    system = OptimizedTradingSystem()

    data_file = "origin_data.csv"
    peak_file = "peak_report_1756977444.json"

    results = system.run_optimized_strategy(data_file, peak_file)